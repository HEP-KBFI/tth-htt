#!/usr/bin/env python
import CombineHarvester.CombineTools.ch as ch
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument('--output',     '-o', dest = 'output',     required = True, help = 'Output directory')
parser.add_argument('--input',      '-i', dest = 'input',      required = True, help = 'Input shapes file')
parser.add_argument('--shapes-dir', '-s', dest = 'shapes_dir', required = True, help = 'Input shapes directory')

args       = parser.parse_args()
shapes_dir = args.shapes_dir
cb         = ch.CombineHarvester()

##########################################################################
# Set the processes and categories
##########################################################################
sig_procs     = ['fakes_data']
bkg_procs_arr = ['EWK', 'TT', 'TTW','TTZ','Rares','tH', 'TTWW', 'ttH_hbb', 'signal']
all_procs     = bkg_procs_arr + sig_procs

bkg_procs = { {% for lepton in leptons %}
  '{{ lepton[0] }}' : bkg_procs_arr,{% endfor %}
}

### BELOW FIRST ENTRY NUMBER (0) IS $BINID AND SECOND 'STRING LABEL' IS $BIN
bins = { {% for lepton in leptons %}
  '{{ lepton[0] }}' : [(0, '{{ lepton[2] }}_shapes')],{% endfor %}
}

channels = [{% for lepton in leptons %}
  '{{ lepton[0] }}',{% endfor %}
]

##########################################################################
# Set input shape files
##########################################################################
files = { {% for lepton in leptons %}
  '{{ lepton[0] }}' : args.input,{% endfor %}
}

inputs = { {% for lepton in leptons %}
  '{{ lepton[0] }}' : {% if lepton[0].startswith('e_') %}'electron'{% elif lepton[0].startswith('mu_') %}'muon'{% else %}None{% endif %},{% endfor %}
}
assert(all(map(lambda x: x is not None, inputs.values())))

##########################################################################
# Create CH entries and load shapes
##########################################################################
for chn in channels:
    ana = ['ttH']
    era = ['13TeV']
    cb.AddObservations(['*'], ana, era, [chn], bins[chn])                        ### DEF LINES
    cb.AddProcesses(['*'],    ana, era, [chn], bkg_procs[chn], bins[chn], False) ### DEF LINES
    cb.AddProcesses(['*'],    ana, era, [chn], sig_procs,      bins[chn], True)  ### DEF LINES

##########################################################################
# Define systematic uncertainties
##########################################################################

#signal = cb.cp().signals().process_set()

#################### Yield systematics ############################

cb.cp().AddSyst( ## Correl. across $CHANNEL and $BIN
    cb, 'EWK_unc', 'lnN', ch.SystMap('channel', 'process')
        (channels, ['EWK'], 1.5)
)
cb.cp().AddSyst( ## Correl. across $CHANNEL and $BIN
    cb, 'TT_unc', 'lnN', ch.SystMap('channel', 'process')
        (channels, ['TT'], 1.5)
)
cb.cp().AddSyst( ## Correl. across $CHANNEL and $BIN
    cb, 'TTW_unc', 'lnN', ch.SystMap('channel', 'process')
        (channels, ['TTW'], 1.2)
)
cb.cp().AddSyst( ## Correl. across $CHANNEL and $BIN
    cb, 'TTZ_unc', 'lnN', ch.SystMap('channel', 'process')
        (channels, ['TTZ'], 1.2)
)
#cb.cp().AddSyst( ## Correl. across $CHANNEL and $BIN
#    cb, 'signal_unc', 'lnN', ch.SystMap('channel', 'process')
#        (channels, ['signal'], 2.0)
#)
cb.cp().AddSyst( ## Correl. across $CHANNEL and $BIN
    cb, 'Rares_unc', 'lnN', ch.SystMap('channel', 'process')
        (channels, ['Rares'], 1.5)
)
cb.cp().AddSyst( ## Correl. across $CHANNEL and $BIN
    cb, 'tH_unc', 'lnN', ch.SystMap('channel', 'process')
        (channels, ['tH'], 2.0)
)
cb.cp().AddSyst( ## Correl. across $CHANNEL and $BIN
    cb, 'TTWW_unc', 'lnN', ch.SystMap('channel', 'process')
        (channels, ['TTWW'], 1.5)
)
cb.cp().AddSyst( ## Correl. across $CHANNEL and $BIN
    cb, 'ttH_hbb_unc', 'lnN', ch.SystMap('channel', 'process')
        (channels, ['ttH_hbb'], 2.0)
)

################### Shape systematics #############################

{% for central_or_shift in central_or_shifts %}
cb.cp().AddSyst(  ## CORREL ACROSS $CHANNEL, CORREL ACROSS $BIN
    cb, '{{ central_or_shift }}', 'shape', ch.SystMap('channel', 'process')
    (channels, all_procs, 1.00)
)
{% endfor %}

##########################################################################
# Load the shapes
##########################################################################
for chn in channels:
    cb.cp().channel([chn]).ExtractShapes(
        '%s/%s/%s' % (shapes_dir, inputs[chn], files[chn]),
        '$BIN/rebinned/$PROCESS', '$BIN/rebinned/$PROCESS_$SYSTEMATIC'
    )

##########################################################################
# Create bin-by-bin
##########################################################################
bbb = ch.BinByBinFactory()
bbb.SetPattern('CMS_$ANALYSIS_$BIN_$ERA_$PROCESS_bin_$#')   #### DEFAULT LINE
bbb.SetAddThreshold(0.1)
bbb.SetMergeThreshold(0.5)  # For now we merge, but to be checked
bbb.SetFixNorm(True)
bbb.MergeAndAdd(cb.cp().backgrounds(), cb)

cb.PrintAll()

##########################################################################
# Write the cards
##########################################################################
writer = ch.CardWriter('$TAG/datacard.txt', '$TAG/shapes.root')
writer.SetWildcardMasses([])  # We don't use the $MASS property here
writer.SetVerbosity(1)
x = writer.WriteCards('%s/cmb' % args.output, cb)  # All cards combined
print(x)
x['%s/cmb/datacard.txt' % args.output].PrintAll()
for chn in channels:  # plus a subdir per channel
    writer.WriteCards('%s/%s' % (args.output, chn), cb.cp().channel([chn]))

